{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8455b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ea849a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 14) (1284, 14) (1267, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        label                                          statement  \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                              subject         speaker           speaker_job  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      state       party barely_true_counts false_counts half_true_counts  \\\n",
       "0     Texas  republican                  0            1                0   \n",
       "1  Virginia    democrat                  0            0                1   \n",
       "2  Illinois    democrat                 70           71              160   \n",
       "3       NaN        none                  7           19                3   \n",
       "4   Florida    democrat                 15            9               20   \n",
       "\n",
       "  mostly_true_counts pants_on_fire_counts              context  \n",
       "0                  0                    0             a mailer  \n",
       "1                  1                    0      a floor speech.  \n",
       "2                163                    9               Denver  \n",
       "3                  5                   44       a news release  \n",
       "4                 19                    2  an interview on CNN  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and load the LIAR dataset\n",
    "COLS = [\n",
    "    \"id\",\"label\",\"statement\",\"subject\",\"speaker\",\"speaker_job\",\"state\",\"party\",\n",
    "    \"barely_true_counts\",\"false_counts\",\"half_true_counts\",\"mostly_true_counts\",\"pants_on_fire_counts\",\n",
    "    \"context\"\n",
    "]\n",
    "\n",
    "def load_tsv(path):\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=None, dtype=str)\n",
    "    df.columns = COLS\n",
    "    return df\n",
    "\n",
    "train_df = load_tsv(\"train.tsv\")\n",
    "valid_df = load_tsv(\"valid.tsv\")\n",
    "test_df  = load_tsv(\"test.tsv\")\n",
    "\n",
    "print(train_df.shape, valid_df.shape, test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "61d5e763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "half-true      2114\n",
       "false          1995\n",
       "mostly-true    1962\n",
       "true           1676\n",
       "barely-true    1654\n",
       "pants-fire      839\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "17b3e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "def make_text(df, use_meta=True):\n",
    "    stmt = df[\"statement\"].fillna(\"\")\n",
    "    \n",
    "    if not use_meta:\n",
    "        return stmt\n",
    "    \n",
    "    subj = df[\"subject\"].fillna(\"\")\n",
    "    ctx  = df[\"context\"].fillna(\"\")\n",
    "    speaker = df[\"speaker\"].fillna(\"\")\n",
    "    party = df[\"party\"].fillna(\"\")\n",
    "    \n",
    "    return stmt + \" [SUBJECT] \" + subj + \" [CONTEXT] \" + ctx + \" [SPEAKER] \" + speaker + \" [PARTY] \" + party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "37363dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker-split sizes: 8299 1941\n",
      "Unique speakers in train: 2328\n",
      "Unique speakers in holdout: 583\n"
     ]
    }
   ],
   "source": [
    "# Muliclass speaker-based split\n",
    "df = train_df.copy()\n",
    "df[\"speaker\"] = df[\"speaker\"].fillna(\"UNKNOWN_SPEAKER\")\n",
    "\n",
    "X = make_text(df, use_meta=True)\n",
    "y = df[\"label\"]\n",
    "groups = df[\"speaker\"]\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, holdout_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train_sp = X.iloc[train_idx]\n",
    "y_train_sp = y.iloc[train_idx]\n",
    "\n",
    "X_holdout_sp = X.iloc[holdout_idx]\n",
    "y_holdout_sp = y.iloc[holdout_idx]\n",
    "\n",
    "print(\"Speaker-split sizes:\", len(X_train_sp), len(X_holdout_sp))\n",
    "print(\"Unique speakers in train:\", df[\"speaker\"].iloc[train_idx].nunique())\n",
    "print(\"Unique speakers in holdout:\", df[\"speaker\"].iloc[holdout_idx].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ef410eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker-holdout accuracy: 0.2375\n",
      "Speaker-holdout macro-F1: 0.2293\n",
      "\n",
      "Classification report (speaker-holdout):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true      0.165     0.190     0.177       306\n",
      "       false      0.247     0.306     0.273       379\n",
      "   half-true      0.266     0.279     0.272       409\n",
      " mostly-true      0.240     0.223     0.231       363\n",
      "  pants-fire      0.280     0.140     0.186       186\n",
      "        true      0.253     0.221     0.236       298\n",
      "\n",
      "    accuracy                          0.238      1941\n",
      "   macro avg      0.242     0.226     0.229      1941\n",
      "weighted avg      0.241     0.238     0.236      1941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate speaker-based split model\n",
    "model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        ngram_range=(1,2),\n",
    "        min_df=2,\n",
    "        max_df=0.9,\n",
    "        max_features=30000\n",
    "    )),\n",
    "    (\"clf\", LinearSVC())\n",
    "])\n",
    "\n",
    "model.fit(X_train_sp, y_train_sp)\n",
    "\n",
    "pred_holdout = model.predict(X_holdout_sp)\n",
    "\n",
    "print(\"Speaker-holdout accuracy:\", round(accuracy_score(y_holdout_sp, pred_holdout), 4))\n",
    "print(\"Speaker-holdout macro-F1:\", round(f1_score(y_holdout_sp, pred_holdout, average=\"macro\"), 4))\n",
    "print(\"\\nClassification report (speaker-holdout):\")\n",
    "print(classification_report(y_holdout_sp, pred_holdout, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5e6fe6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID accuracy: 0.2687 macro-F1: 0.2774\n",
      "TEST  accuracy: 0.2636 macro-F1: 0.2613\n"
     ]
    }
   ],
   "source": [
    "# Multiclass standard split model\n",
    "X_train = make_text(train_df, use_meta=True)\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "X_valid = make_text(valid_df, use_meta=True)\n",
    "y_valid = valid_df[\"label\"]\n",
    "\n",
    "X_test  = make_text(test_df, use_meta=True)\n",
    "y_test  = test_df[\"label\"]\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_valid = model.predict(X_valid)\n",
    "pred_test  = model.predict(X_test)\n",
    "\n",
    "print(\"VALID accuracy:\", round(accuracy_score(y_valid, pred_valid), 4),\n",
    "      \"macro-F1:\", round(f1_score(y_valid, pred_valid, average=\"macro\"), 4))\n",
    "print(\"TEST  accuracy:\", round(accuracy_score(y_test, pred_test), 4),\n",
    "      \"macro-F1:\", round(f1_score(y_test, pred_test, average=\"macro\"), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "51918269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50, 54, 61, 31, 12, 29],\n",
       "       [48, 72, 48, 34, 28, 33],\n",
       "       [43, 51, 73, 43,  7, 31],\n",
       "       [35, 31, 57, 66,  8, 54],\n",
       "       [16, 29, 10,  8, 41, 12],\n",
       "       [16, 28, 39, 42,  1, 43]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix for validation set\n",
    "labels = sorted(y_train.unique())\n",
    "confusion_matrix(y_valid, pred_valid, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9e199743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification conversion\n",
    "TRUEISH  = {\"true\", \"mostly-true\", \"half-true\"}\n",
    "FALSEISH = {\"false\", \"barely-true\", \"pants-fire\"}\n",
    "\n",
    "def to_binary(labels: pd.Series) -> pd.Series:\n",
    "    return labels.map(lambda x: 1 if x in TRUEISH else 0)\n",
    "\n",
    "y_train_bin = to_binary(train_df[\"label\"])\n",
    "y_valid_bin = to_binary(valid_df[\"label\"])\n",
    "y_test_bin  = to_binary(test_df[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "01ec69bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary VALID accuracy: 0.6433\n",
      "Binary VALID F1: 0.6602\n",
      "\n",
      "Binary classification report (VALID):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.631     0.619     0.625       616\n",
      "           1      0.654     0.666     0.660       668\n",
      "\n",
      "    accuracy                          0.643      1284\n",
      "   macro avg      0.643     0.642     0.642      1284\n",
      "weighted avg      0.643     0.643     0.643      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary classification model\n",
    "bin_model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        ngram_range=(1,2),\n",
    "        min_df=2,\n",
    "        max_df=0.9,\n",
    "        max_features=30000\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=800,\n",
    "        solver=\"liblinear\",\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "X_train_bin = make_text(train_df, use_meta=True)\n",
    "X_valid_bin = make_text(valid_df, use_meta=True)\n",
    "X_test_bin  = make_text(test_df,  use_meta=True)\n",
    "\n",
    "bin_model.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "probs_valid = bin_model.predict_proba(X_valid_bin)[:, 1]  # P(true-ish)\n",
    "pred_valid_bin = (probs_valid >= 0.5).astype(int)\n",
    "\n",
    "print(\"Binary VALID accuracy:\", round(accuracy_score(y_valid_bin, pred_valid_bin), 4))\n",
    "print(\"Binary VALID F1:\", round(f1_score(y_valid_bin, pred_valid_bin), 4))\n",
    "print(\"\\nBinary classification report (VALID):\")\n",
    "print(classification_report(y_valid_bin, pred_valid_bin, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9f332b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold=0.55 | coverage=0.77 | acc=0.682 | f1=0.690\n",
      "threshold=0.60 | coverage=0.56 | acc=0.711 | f1=0.722\n",
      "threshold=0.65 | coverage=0.38 | acc=0.753 | f1=0.759\n",
      "threshold=0.70 | coverage=0.24 | acc=0.806 | f1=0.804\n",
      "threshold=0.75 | coverage=0.14 | acc=0.835 | f1=0.824\n",
      "threshold=0.80 | coverage=0.07 | acc=0.915 | f1=0.907\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with abstention\n",
    "def evaluate_with_abstention(y_true, probs, threshold=0.7):\n",
    "    y_true = np.asarray(y_true, dtype=int)\n",
    "    probs = np.asarray(probs, dtype=float)\n",
    "\n",
    "    confident = (probs >= threshold) | (probs <= 1 - threshold)\n",
    "    coverage = confident.mean()\n",
    "\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    if confident.sum() == 0:\n",
    "        return coverage, np.nan, np.nan\n",
    "\n",
    "    acc = accuracy_score(y_true[confident], preds[confident])\n",
    "    f1  = f1_score(y_true[confident], preds[confident])\n",
    "\n",
    "    return coverage, acc, f1\n",
    "\n",
    "for t in [0.55, 0.60, 0.65, 0.70, 0.75, 0.80]:\n",
    "    coverage, acc, f1 = evaluate_with_abstention(y_valid_bin, probs_valid, threshold=t)\n",
    "    print(f\"threshold={t:.2f} | coverage={coverage:.2f} | acc={acc:.3f} | f1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a48fb627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST with abstention (t=0.7): coverage=0.24 | acc=0.799 | f1=0.826\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation with abstention\n",
    "t = 0.70  \n",
    "\n",
    "probs_test = bin_model.predict_proba(X_test_bin)[:, 1]\n",
    "\n",
    "coverage, acc, f1 = evaluate_with_abstention(y_test_bin, probs_test, threshold=t)\n",
    "print(f\"TEST with abstention (t={t}): coverage={coverage:.2f} | acc={acc:.3f} | f1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aea47cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function with abstention\n",
    "def predict_sentence(text, model, threshold=0.70):\n",
    "    \n",
    "    proba_trueish = model.predict_proba([text])[0, 1]  # P(true-ish)\n",
    "    proba_falseish = 1 - proba_trueish\n",
    "    \n",
    "   \n",
    "    confident = (proba_trueish >= threshold) or (proba_trueish <= 1 - threshold)\n",
    "    \n",
    "    if not confident:\n",
    "        return {\n",
    "            \"decision\": \"ABSTAIN (not confident)\",\n",
    "            \"p_trueish\": float(proba_trueish),\n",
    "            \"p_falseish\": float(proba_falseish),\n",
    "        }\n",
    "    \n",
    "    decision = \"TRUE-ISH\" if proba_trueish >= 0.5 else \"FALSE-ISH\"\n",
    "    return {\n",
    "        \"decision\": decision,\n",
    "        \"p_trueish\": float(proba_trueish),\n",
    "        \"p_falseish\": float(proba_falseish),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3c81c08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Earth orbits the Sun once every year.\n",
      "{'decision': 'ABSTAIN (not confident)', 'p_trueish': 0.6076728739748772, 'p_falseish': 0.39232712602512276}\n",
      "------------------------------------------------------------\n",
      "Vaccines cause autism.\n",
      "{'decision': 'ABSTAIN (not confident)', 'p_trueish': 0.3769723661386222, 'p_falseish': 0.6230276338613778}\n",
      "------------------------------------------------------------\n",
      "The unemployment rate fell last month according to the Bureau of Labor Statistics.\n",
      "{'decision': 'ABSTAIN (not confident)', 'p_trueish': 0.37455311422243326, 'p_falseish': 0.6254468857775668}\n",
      "------------------------------------------------------------\n",
      "The President was born on Mars.\n",
      "{'decision': 'ABSTAIN (not confident)', 'p_trueish': 0.421302881909816, 'p_falseish': 0.578697118090184}\n",
      "------------------------------------------------------------\n",
      "Drinking bleach cures infections.\n",
      "{'decision': 'ABSTAIN (not confident)', 'p_trueish': 0.4505471595313009, 'p_falseish': 0.5494528404686991}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example predictions\n",
    "threshold = 0.70\n",
    "\n",
    "samples = [\n",
    "    \"The Earth orbits the Sun once every year.\",\n",
    "    \"Vaccines cause autism.\",\n",
    "    \"The unemployment rate fell last month according to the Bureau of Labor Statistics.\",\n",
    "    \"The President was born on Mars.\",\n",
    "    \"Drinking bleach cures infections.\"\n",
    "]\n",
    "\n",
    "for s in samples:\n",
    "    print(s)\n",
    "    print(predict_sentence(s, bin_model, threshold=threshold))\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f3d2fb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confident examples: 298 out of 1267\n",
      "\n",
      "STATEMENT: Building a wall on the U.S.-Mexico border will take literally years.\n",
      "p_trueish: 0.253 | PRED: FALSE-ISH | TRUE: TRUE-ISH\n",
      "\n",
      "STATEMENT: Suzanne Bonamici supports a plan that will cut choice for Medicare Advantage seniors.\n",
      "p_trueish: 0.225 | PRED: FALSE-ISH | TRUE: TRUE-ISH\n",
      "\n",
      "STATEMENT: When asked by a reporter whether hes at the center of a criminal scheme to violate campaign laws, Gov. Scott Walker nodded yes.\n",
      "p_trueish: 0.297 | PRED: FALSE-ISH | TRUE: FALSE-ISH\n",
      "\n",
      "STATEMENT: We know there are more Democrats in Georgia than Republicans. We know that for a fact.\n",
      "p_trueish: 0.703 | PRED: TRUE-ISH | TRUE: FALSE-ISH\n",
      "\n",
      "STATEMENT: Denali is the Kenyan word for black power.\n",
      "p_trueish: 0.209 | PRED: FALSE-ISH | TRUE: FALSE-ISH\n",
      "\n",
      "STATEMENT: Unfortunately we have documented instances where people defecated in the (Statehouse) building.\n",
      "p_trueish: 0.179 | PRED: FALSE-ISH | TRUE: FALSE-ISH\n",
      "\n",
      "STATEMENT: Says Charlie Crist is embroiled in a fraud case for steering taxpayer money to a de facto Ponzi scheme.\n",
      "p_trueish: 0.293 | PRED: FALSE-ISH | TRUE: FALSE-ISH\n",
      "\n",
      "STATEMENT: Says Thomas Jefferson said, You might be able to fool the people for awhile, and they may go astray, but sooner or later the American people are going to wake up and they will correct the course.\n",
      "p_trueish: 0.28 | PRED: FALSE-ISH | TRUE: TRUE-ISH\n",
      "\n",
      "STATEMENT: The federal minimum wage is worth about 20 percent less than it was when Ronald Reagan gave his first address to a joint session of Congress.\n",
      "p_trueish: 0.854 | PRED: TRUE-ISH | TRUE: TRUE-ISH\n",
      "\n",
      "STATEMENT: Already, a prototype driverless car has traveled more than 300,000 miles in the crowded maze of California streets without a single accident.\n",
      "p_trueish: 0.795 | PRED: TRUE-ISH | TRUE: TRUE-ISH\n"
     ]
    }
   ],
   "source": [
    "# Analyze confident test set examples\n",
    "t = 0.70\n",
    "X_test_bin = make_text(test_df, use_meta=True)\n",
    "y_test_bin = to_binary(test_df[\"label\"])\n",
    "\n",
    "probs_test = bin_model.predict_proba(X_test_bin)[:, 1]\n",
    "conf = (probs_test >= t) | (probs_test <= 1 - t)\n",
    "\n",
    "conf_idx = np.where(conf)[0]\n",
    "print(\"Confident examples:\", len(conf_idx), \"out of\", len(test_df))\n",
    "\n",
    "for i in conf_idx[:10]:\n",
    "    s = test_df.loc[i, \"statement\"]\n",
    "    true_lab = \"TRUE-ISH\" if y_test_bin.iloc[i] == 1 else \"FALSE-ISH\"\n",
    "    p = probs_test[i]\n",
    "    pred = \"TRUE-ISH\" if p >= 0.5 else \"FALSE-ISH\"\n",
    "    print(\"\\nSTATEMENT:\", s)\n",
    "    print(\"p_trueish:\", round(float(p), 3), \"| PRED:\", pred, \"| TRUE:\", true_lab)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
